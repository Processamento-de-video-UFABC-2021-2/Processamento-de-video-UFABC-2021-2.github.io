{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"relatorio_6.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"QQBlruKffK71","executionInfo":{"status":"ok","timestamp":1626693240541,"user_tz":180,"elapsed":905,"user":{"displayName":"Jessi Leandro Castro","photoUrl":"","userId":"13748011766331206770"}}},"source":["import cv2 as cv\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import math as Math\n","from google.colab.patches import cv2_imshow # cv2_imshow"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"LlIrfEhyY16b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1626693263336,"user_tz":180,"elapsed":20939,"user":{"displayName":"Jessi Leandro Castro","photoUrl":"","userId":"13748011766331206770"}},"outputId":"ba3bed4d-c845-4a6f-dd21-bf5a7ba7311f"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_i8L1W1wok_f","executionInfo":{"status":"ok","timestamp":1626697362535,"user_tz":180,"elapsed":261,"user":{"displayName":"Jessi Leandro Castro","photoUrl":"","userId":"13748011766331206770"}}},"source":["pathOrigin = '/content/drive/My Drive/processamento-de-video/R6/'"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sO9gl3mfXeoj"},"source":["É conhecido que os \"corners\", sendo os cantos ou vértices, são regiões da imagem com larga variação de intensidade em todas as direções.\n","\n","Dessa forma, estudaremos a detecção dos \"corners\" a partir do modelo de Chris Harris, via a função `cornerHarris()` da biblioteca OpenCV, a qual leva o nome de seu criador em sua nomenclatura."]},{"cell_type":"markdown","metadata":{"id":"Eco2WSGJXnH5"},"source":["Execução:\n","\n","Segundo a documentação, a imagem de input utilizada na função \"should be grayscale and float32 type.\", logo realizaremos as seguintes ações:\n","\n","1. Leitura da imagem passando a flag `IMREAD_GRAYSCALE`, convertendo-a para grayscale\n","2. Transformando a imagem para o tipo `float32` via bibloteca NumPy\n","\n","Para fins de testes, foram propostos duas maneiras de ler a imagem em `grayscale`, uma utilizando a flag no `imread()` e outra no `cvtColor()`, pois a documentação indica que há diferença.\n","\n","> \"When using IMREAD_GRAYSCALE, the codec's internal grayscale conversion will be used, if available. Results may differ to the output of cvtColor()\"\n","\n","Entretanto, não houveram diferenças visíveis no resultado da detecção dos vértices"]},{"cell_type":"code","metadata":{"id":"kX798x2RXsDm","executionInfo":{"status":"ok","timestamp":1626698219401,"user_tz":180,"elapsed":241,"user":{"displayName":"Jessi Leandro Castro","photoUrl":"","userId":"13748011766331206770"}}},"source":["# Função utilitária para transformar a imagem para \"grayscale\"\n","def grayMethod(method, fileName):\n","  # Caminho completo da imagem\n","  pathImage = pathOrigin + fileName\n","  if method == 1 :\n","    # Passando a flag cv.IMREAD_GRAYSCALE para a função imread\n","    return cv.imread(pathImage, cv.IMREAD_GRAYSCALE)\n","  elif method == 2 :\n","    image = cv.imread(pathImage)\n","    # Passando a flag cv.COLOR_BGR2GRAY para a função cvtColor\n","    return cv.cvtColor(image,cv.COLOR_BGR2GRAY)"],"execution_count":37,"outputs":[]},{"cell_type":"code","metadata":{"id":"z2_Qdlb4XupT","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1N89M60-d-RMEsDUQ8RB06pQ98FAyYIvk"},"executionInfo":{"status":"ok","timestamp":1626698225255,"user_tz":180,"elapsed":4248,"user":{"displayName":"Jessi Leandro Castro","photoUrl":"","userId":"13748011766331206770"}},"outputId":"c9cc2744-cd75-4f65-d3b1-599bd0268cc5"},"source":["def harrisCornerDetect(method, fileName):\n","  imageGray = grayMethod(method, fileName)\n","  # Transformando para tipo \"float32\"\n","  imageInModel = np.float32(imageGray)\n","  # Execução da função cornerHarris com os parâmetros indicados na documentação\n","  corners = cv.cornerHarris(imageInModel,2,3,0.04)\n","  # Dilatação do resultado para marcação dos corners\n","  corners = cv.dilate(corners,None)\n","  \n","  # Leitura da imagem original\n","  pathImage = pathOrigin + fileName\n","  image = cv.imread(pathImage)\n","  # Adição dos corners\n","  image[corners>0.01*corners.max()]=[0,0,255]\n","  cv2_imshow(image)\n"," \n","\n","harrisCornerDetect(1, 'corner-image.jpg')\n","harrisCornerDetect(1, 'gitlab-logo.jpg')\n","\n","harrisCornerDetect(2, 'corner-image.jpg')\n","harrisCornerDetect(2, 'gitlab-logo.jpg')"],"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"markdown","metadata":{"id":"advYo2vbX0Lw"},"source":["Alguns anos após a metodologia proposta por Chris Harris, J. Shi e C. Tomasi propuseram uma pequena modificação no código, na qual é definido um \"threshold\" e caso o valor do píxel seja maior que o threshold, o mesmo será considerado um \"corner\"."]},{"cell_type":"markdown","metadata":{"id":"ydRD4EP9X3PJ"},"source":["Execução:\n","\n","Diferentemente da metodologia de Harris, segundo a documentação não é necessário que a imagem utilizada seja do tipo float32, porém, como usual, a imagem deve estar em grayscale.\n","\n","Dessa forma foram realizadas as seguintes ações:\n","\n","1. Leitura da imagem passando a flag `IMREAD_GRAYSCALE`, convertendo-a para grayscale\n","2. Utilizada a função proposta por Shi-Tomasi\n","3. Executada a função int0 da biblioteca Numpy para indexar os corners em números inteiros\n","4. Adicionado, via função cv.circle(), círculos nos N corners mais relevantes, indicados pelo valor \"corners\" na chamada da função `shiTomasiCornerDetect()`\n"]},{"cell_type":"markdown","metadata":{"id":"Vu6EkXzAXe8o"},"source":["Novamente foram testadas duas maneiras para leitura da imagem em \n","\n","1.   Item da lista\n","2.   Item da lista\n","\n","\"GrayScale\", e novamente não houveram diferenças notáveis."]},{"cell_type":"code","metadata":{"id":"eWbHHHqDX_gn","colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1DDFRqPdzMscdm33o1jen6z13MN4CT8st"},"executionInfo":{"status":"ok","timestamp":1626698235305,"user_tz":180,"elapsed":9020,"user":{"displayName":"Jessi Leandro Castro","photoUrl":"","userId":"13748011766331206770"}},"outputId":"003adcbd-4a73-4a75-f605-3fffa4703366"},"source":["def shiTomasiCornerDetect(method, fileName, corners, qualityLevel):\n","  # Imagem para GrayScale\n","  imageGray = grayMethod(method, fileName)\n","  # Execução da função goodFeaturesToTrack \n","  corners = cv.goodFeaturesToTrack(imageGray,corners,qualityLevel,10)\n","  corners = np.int0(corners)\n","  # Leitura da imagem original\n","  pathImage = pathOrigin + fileName\n","  image = cv.imread(pathImage)\n","  # Adição dos corners como círculos, com a função cv.circle, na imagem original\n","  for i in corners:\n","    x,y = i.ravel()\n","    cv.circle(image,(x,y),3,255,-1)\n","  # Mostra a imagem\n","  cv2_imshow(image)\n","\n"," \n","\n","#shiTomasiCornerDetect(1, 'corner-image.jpeg', 5, 0.5)\n","#shiTomasiCornerDetect(1, 'gitlab-logo.jpg', 5, 0.5)\n","\n","shiTomasiCornerDetect(2, 'corner-image.jpg', 5, 0.1)\n","shiTomasiCornerDetect(2, 'gitlab-logo.jpg', 5, 0.1)\n","shiTomasiCornerDetect(2, 'corner-image.jpg', 10, 0.1)\n","shiTomasiCornerDetect(2, 'gitlab-logo.jpg', 10, 0.1)\n","\n","\n","shiTomasiCornerDetect(2, 'corner-image.jpg', 5, 0.5)\n","shiTomasiCornerDetect(2, 'gitlab-logo.jpg', 5, 0.5)\n","shiTomasiCornerDetect(2, 'corner-image.jpg', 10, 0.5)\n","shiTomasiCornerDetect(2, 'gitlab-logo.jpg', 10, 0.5)\n","\n","\n"],"execution_count":39,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"hLSltvyZqgrS","executionInfo":{"status":"ok","timestamp":1626697191680,"user_tz":180,"elapsed":243,"user":{"displayName":"Jessi Leandro Castro","photoUrl":"","userId":"13748011766331206770"}}},"source":["def showImg(img):\n","  # Faz a leitura do objeto e exibe a imagem em tela, por padrão exibe em BGR,\n","  # assim como em \"imread\"\n","  cv2_imshow(img)\n"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ObYrhRLzytGm"},"source":["SIFT (Scale Invariant Feature Transform), é um algoritmo de visão computacional publicado por David Lowe. Ele é composto por duas partes distintas, que são: o detector e o descritor.\n","\n","O detector SIFT é baseado em cálculos de diferença de Gaussianas e o descritor\n","SIFT utiliza histogramas de gradientes orientados para descrever a vizinhança\n","local dos pontos de interesse."]},{"cell_type":"markdown","metadata":{"id":"0e0FrOKa0nNG"},"source":["Execução:\n","\n","1. Leitura da imagem passando a flag `IMREAD_GRAYSCALE`, convertendo-a para grayscale\n","2. Criação de um objeto SIFT, utilizando a função `SIFT_create` do openCV, porposta pelo tutorial.\n","3. Obtenção dos pontos-chave atravez do metodo `detectAndCompute`, do objroto SIFT criado do passo anterior, passando como parametro a imagem em grayscale, obtida no passo 1.\n","4. Usar a função `drawKeypoints`do openCV para desenhar os pontos-chave, ela recebe respectivament os parametro: a imagem em grayscale, os pontos-chave (obtidos no passo anterior), imagem original, pro fim é passada a flag `DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS`."]},{"cell_type":"code","metadata":{"id":"6qkrjGgyO0p0","colab":{"base_uri":"https://localhost:8080/","height":350},"executionInfo":{"status":"error","timestamp":1626701447385,"user_tz":180,"elapsed":287,"user":{"displayName":"Jessi Leandro Castro","photoUrl":"","userId":"13748011766331206770"}},"outputId":"59066497-9aeb-4d38-8ccb-505a15fe6762"},"source":["def keyPointsDetect(fileName):\n","\n","  pathImage = pathOrigin + fileName\n","  image = cv.imread(pathImage)\n","\n","  # Imagem para GrayScale\n","  imageGray= cv.cvtColor(image,cv.COLOR_BGR2GRAY)\n","\n","  # Cria o objeto SIFT para tratar a imagem\n","  sift = cv.SIFT_create()\n","\n","  # Executa a função detectAndCompute do objeto SIFT, que retorna os pontos-chave\n","  # e os descritores\n","  kp, des = sift.detectAndCompute(imageGray, None)\n","\n","  # Desenha os pontos-chave na imagem\n","  img = cv.drawKeypoints(imageGray, kp, image, flags=cv.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n","\n","  # Exibe a imagem\n","  showImg(imageGray)\n","\n","\n","keyPointsDetect('corner-image.jpg')\n","keyPointsDetect('gitlab-logo.jpg')\n","keyPointsDetect('ufabc.jpeg')\n","\n"],"execution_count":42,"outputs":[{"output_type":"error","ename":"AttributeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-42-975a8bc3b530>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mkeyPointsDetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'corner-image.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mkeyPointsDetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gitlab-logo.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mkeyPointsDetect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ufabc.jpeg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-42-975a8bc3b530>\u001b[0m in \u001b[0;36mkeyPointsDetect\u001b[0;34m(fileName)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m# Cria o objeto SIFT para tratar a imagem\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0msift\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSIFT_create\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;31m# Executa a função detectAndCompute do objeto SIFT, que retorna os pontos-chave\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: module 'cv2.cv2' has no attribute 'SIFT_create'"]}]},{"cell_type":"markdown","metadata":{"id":"yqjY2MvEv23b"},"source":["A função `SIFT_create` do openCV não estava funcionando no colab, então a obtenção das imagens foi feito localmente usando o mesmo código acima, as imagens obtidas são exibidas abaixo.\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"10zY1GVcfrF4d-t1CudhujsKcDkwJYXKh"},"id":"tbAJvWYcvDR6","executionInfo":{"status":"ok","timestamp":1626697831342,"user_tz":180,"elapsed":5290,"user":{"displayName":"Jessi Leandro Castro","photoUrl":"","userId":"13748011766331206770"}},"outputId":"5b2912db-dd55-4219-b047-7458727fccaf"},"source":["def openImage(fileName):\n","  pathImage = pathOrigin + fileName\n","  image = cv.imread(pathImage)\n","  showImg(image)\n","\n","\n","openImage('corner-image_sift_keypoints.jpg')\n","openImage('gitlab_sift_keypoints.jpg')\n","openImage('ufabc_sift_keypoints.jpg')\n"],"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}